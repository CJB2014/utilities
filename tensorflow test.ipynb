{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.python.framework import ops\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "X_val = mnist.validation.images\n",
    "y_val = mnist.validation.labels\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],-1).T\n",
    "y_train = y_train.reshape(y_train.shape[0],-1).T\n",
    "X_val = X_val.reshape(X_val.shape[0],-1).T\n",
    "y_val = y_val.reshape(y_val.shape[0],-1).T\n",
    "X_test = X_test.reshape(X_test.shape[0],-1).T\n",
    "y_test = y_test.reshape(y_test.shape[0],-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 55000)\n",
      "(10, 55000)\n",
      "(784, 5000)\n",
      "(784, 10000)\n",
      "(10, 10000)\n",
      "Number a training example: 55000\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print('Number a training example: ' + str(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_creation(n_x,n_y):\n",
    "    X = tf.placeholder(tf.float32, shape = [n_x,None], name = 'X')\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y,None], name = 'Y')\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "def initialize_parameters():\n",
    "    W1 = tf.get_variable('W1',[128,784], initializer = tf.contrib.layers.xavier_initializer(seed = 3))\n",
    "    b1 = tf.get_variable('b1',[128,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable('W2',[40,128], initializer = tf.contrib.layers.xavier_initializer(seed = 3))\n",
    "    b2 = tf.get_variable('b2', [40,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable('W3',[10,40], initializer = tf.contrib.layers.xavier_initializer(seed = 3))\n",
    "    b3 = tf.get_variable('b3',[10,1], initializer = tf.zeros_initializer())\n",
    "    parameters = {\n",
    "        'W1':W1,\n",
    "        'b1':b1,\n",
    "        'W2':W2,\n",
    "        'b2':b2,\n",
    "        'W3':W3,\n",
    "        'b3':b3\n",
    "    }\n",
    "    return parameters\n",
    "\n",
    "def forward_prop(X,parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)\n",
    "    return Z3 \n",
    "\n",
    "def compute_cost(Z3,Y):\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    return cost \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(128, 784) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(128, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(40, 128) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(40, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 32, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "    \n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    \n",
    "    \n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k + 1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k + 1) * mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)     \n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:, mini_batch_size * num_complete_minibatches : m]\n",
    "        mini_batch_Y = shuffled_Y[:, mini_batch_size * num_complete_minibatches : m]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, y_train, X_val, y_val, learning_rate = 0.001, num_epochs = 1500, minibatch_size = 32 , print_cost = True):\n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(3)\n",
    "    seed = 3\n",
    "    (n_x,m) = X_train.shape\n",
    "    n_y = y_train.shape[0]\n",
    "    costs = []\n",
    "    \n",
    "    X,Y = placeholder_creation(n_x,n_y)\n",
    "    \n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    Z3 = forward_prop(X,parameters)\n",
    "    \n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0.\n",
    "            num_minibatches = int(m/minibatch_size)\n",
    "            seed = seed + 1 \n",
    "            minibatches = random_mini_batches(X_train,y_train,minibatch_size, seed)\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X,minibatch_Y) = minibatch\n",
    "                _ , minibatch_cost = sess.run([optimizer,cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "                epoch_cost += minibatch_cost/num_minibatches\n",
    "            if print_cost == True and epoch % 100 == 0 :\n",
    "                print('Cost after epoch %i: %f' %(epoch, epoch_cost))\n",
    "            if print_cost ==True and epoch%5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iteration (per tens)')\n",
    "        plt.title('Learning rate = ' + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        parameters = sess.run(parameters)\n",
    "        print('Paramateres have been trained')\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(Z3),tf.argmax(Y))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "        \n",
    "        print('train', accuracy.eval({X:X_train, Y:y_train}))\n",
    "        print('eval',accuracy.eval({X:X_val, Y:y_val}))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [784, X.shape[1]])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.877333\n",
      "Cost after epoch 100: 0.113026\n",
      "Cost after epoch 200: 0.058836\n",
      "Cost after epoch 300: 0.034412\n",
      "Cost after epoch 400: 0.021098\n",
      "Cost after epoch 500: 0.013456\n",
      "Cost after epoch 600: 0.008974\n",
      "Cost after epoch 700: 0.006295\n",
      "Cost after epoch 800: 0.004638\n",
      "Cost after epoch 900: 0.003579\n",
      "Cost after epoch 1000: 0.002869\n",
      "Cost after epoch 1100: 0.002365\n",
      "Cost after epoch 1200: 0.001993\n",
      "Cost after epoch 1300: 0.001710\n",
      "Cost after epoch 1400: 0.001492\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJwwzMyvECcPMzAr5/1T3RzbK2gMgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc010f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramateres have been trained\n",
      "train 1.0\n",
      "eval 0.9796\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is:0.9764\n"
     ]
    }
   ],
   "source": [
    "pred = predict(X_test, parameters)\n",
    "pp = np.argmax(y_test, axis = 0)\n",
    "\n",
    "acc = np.sum(np.where(pp==pred,1,0))/10000\n",
    "print('Accuracy on test set is:' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
